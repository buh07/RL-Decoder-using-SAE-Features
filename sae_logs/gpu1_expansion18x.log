/scratch2/f004ndc/RL-Decoder with SAE Features/src/sae_training.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = GradScaler() if self.use_amp else None
/scratch2/f004ndc/RL-Decoder with SAE Features/src/sae_training.py:196: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(dtype=self.dtype):
/scratch2/f004ndc/RL-Decoder with SAE Features/src/sae_training.py:223: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  self.scheduler.step()
[Dataset] Found 1 shards in /tmp/gpt2_gsm8k_acts/gsm8k/train
[training] Starting SAE training
  Config: 768D â†’ 13824D
  Device: cuda:1, AMP: True
  Max epochs: 10, Max steps: None

[epoch 0] avg_loss=301.9273, time=3.9s (18 steps)
[epoch 1] avg_loss=208.4450, time=3.5s (18 steps)
[epoch 2] avg_loss=177.4107, time=3.5s (18 steps)
[epoch 3] avg_loss=139.7307, time=3.4s (18 steps)
[epoch 4] avg_loss=103.0548, time=3.5s (18 steps)
[05] step=000100 | loss=71.8499 (recon=71.8485, l1=1.2803, decorr=0.0013) | sparsity=49.68% | lr=1.00e-05 | 127.1ms
[epoch 5] avg_loss=73.0499, time=3.5s (18 steps)
[epoch 6] avg_loss=51.8550, time=3.4s (18 steps)
[epoch 7] avg_loss=38.0867, time=3.5s (18 steps)
[epoch 8] avg_loss=29.1414, time=3.5s (18 steps)
[epoch 9] avg_loss=22.8198, time=3.5s (18 steps)

[training] Complete!
  Total steps: 180
  Total time: 35.0s
  Avg time/step: 194.6ms
[checkpoint] saved to /scratch2/f004ndc/RL-Decoder with SAE Features/checkpoints/sae/sae_768d_final.pt

[done] Training summary:
  total_steps: 180
  total_time_seconds: 35.03570943698287
  avg_time_per_step_ms: 194.6428302054604
  final_loss: 20.634967803955078
  model_saved: /scratch2/f004ndc/RL-Decoder with SAE Features/checkpoints/sae
